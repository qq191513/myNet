epoch: 0 , global_step: 704 , train loss: 471.784001 , valid precision: 0.497000 , valid loss: 353.908324
epoch: 1 , global_step: 1408 , train loss: 313.326210 , valid precision: 0.660400 , valid loss: 261.102191
epoch: 2 , global_step: 2112 , train loss: 254.514248 , valid precision: 0.721400 , valid loss: 222.428060
epoch: 3 , global_step: 2816 , train loss: 222.823424 , valid precision: 0.766000 , valid loss: 197.853804
epoch: 4 , global_step: 3520 , train loss: 203.927273 , valid precision: 0.794200 , valid loss: 184.447829
epoch: 5 , global_step: 4224 , train loss: 191.761939 , valid precision: 0.795200 , valid loss: 183.559968
epoch: 6 , global_step: 4928 , train loss: 184.620559 , valid precision: 0.814600 , valid loss: 176.767969
epoch: 7 , global_step: 5632 , train loss: 177.515691 , valid precision: 0.828000 , valid loss: 170.693276
epoch: 8 , global_step: 6336 , train loss: 172.425012 , valid precision: 0.833400 , valid loss: 172.976565
epoch: 9 , global_step: 7040 , train loss: 168.402377 , valid precision: 0.840200 , valid loss: 170.867209
epoch: 10 , global_step: 7744 , train loss: 164.647801 , valid precision: 0.837800 , valid loss: 170.573025
epoch: 11 , global_step: 8448 , train loss: 161.495754 , valid precision: 0.845800 , valid loss: 169.710274
epoch: 12 , global_step: 9152 , train loss: 158.916593 , valid precision: 0.847600 , valid loss: 167.575955
epoch: 13 , global_step: 9856 , train loss: 156.208460 , valid precision: 0.854000 , valid loss: 166.099319
epoch: 14 , global_step: 10560 , train loss: 153.267967 , valid precision: 0.849600 , valid loss: 165.670006
epoch: 15 , global_step: 11264 , train loss: 152.000128 , valid precision: 0.849600 , valid loss: 165.927774
epoch: 16 , global_step: 11968 , train loss: 150.794201 , valid precision: 0.861200 , valid loss: 164.980686
epoch: 17 , global_step: 12672 , train loss: 148.411277 , valid precision: 0.849800 , valid loss: 166.193993
epoch: 18 , global_step: 13376 , train loss: 147.117056 , valid precision: 0.860600 , valid loss: 162.913444
epoch: 19 , global_step: 14080 , train loss: 144.269958 , valid precision: 0.866400 , valid loss: 166.220260
epoch: 20 , global_step: 14784 , train loss: 144.018434 , valid precision: 0.861600 , valid loss: 163.854500
epoch: 21 , global_step: 15488 , train loss: 142.307335 , valid precision: 0.873200 , valid loss: 162.220796
epoch: 22 , global_step: 16192 , train loss: 141.465562 , valid precision: 0.854800 , valid loss: 167.015197
epoch: 23 , global_step: 16896 , train loss: 139.848224 , valid precision: 0.855200 , valid loss: 172.274994
epoch: 24 , global_step: 17600 , train loss: 140.411473 , valid precision: 0.865000 , valid loss: 161.520163
epoch: 25 , global_step: 18304 , train loss: 139.553964 , valid precision: 0.860600 , valid loss: 164.787677
epoch: 26 , global_step: 19008 , train loss: 137.010923 , valid precision: 0.867200 , valid loss: 164.056288
epoch: 27 , global_step: 19712 , train loss: 136.257491 , valid precision: 0.866400 , valid loss: 164.304406
epoch: 28 , global_step: 20416 , train loss: 136.736944 , valid precision: 0.870800 , valid loss: 162.746918
epoch: 29 , global_step: 21120 , train loss: 135.973919 , valid precision: 0.861800 , valid loss: 164.891259
epoch: 30 , global_step: 21824 , train loss: 134.645781 , valid precision: 0.867000 , valid loss: 164.536835
epoch: 31 , global_step: 22528 , train loss: 134.413765 , valid precision: 0.862800 , valid loss: 164.335703
epoch: 32 , global_step: 23232 , train loss: 134.830335 , valid precision: 0.869800 , valid loss: 165.805215
epoch: 33 , global_step: 23936 , train loss: 132.570075 , valid precision: 0.868800 , valid loss: 164.704309
epoch: 34 , global_step: 24640 , train loss: 132.785561 , valid precision: 0.868200 , valid loss: 166.850609
epoch: 35 , global_step: 25344 , train loss: 131.410605 , valid precision: 0.872400 , valid loss: 162.194713
epoch: 36 , global_step: 26048 , train loss: 131.983576 , valid precision: 0.869200 , valid loss: 162.539662
epoch: 37 , global_step: 26752 , train loss: 130.720212 , valid precision: 0.870200 , valid loss: 169.434397
epoch: 38 , global_step: 27456 , train loss: 131.356831 , valid precision: 0.873200 , valid loss: 165.285816
epoch: 39 , global_step: 28160 , train loss: 130.408541 , valid precision: 0.876000 , valid loss: 167.388219
epoch: 40 , global_step: 28864 , train loss: 130.795723 , valid precision: 0.872800 , valid loss: 164.147354
