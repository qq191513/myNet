epoch: 0 , global_step: 352 , train loss: 755.902487 , valid precision: 0.465000 , valid loss: 593.029646
epoch: 1 , global_step: 704 , train loss: 520.786102 , valid precision: 0.625400 , valid loss: 417.976019
epoch: 2 , global_step: 1056 , train loss: 403.232198 , valid precision: 0.698600 , valid loss: 329.161158
epoch: 3 , global_step: 1408 , train loss: 335.195996 , valid precision: 0.759400 , valid loss: 282.415194
epoch: 4 , global_step: 1760 , train loss: 289.577785 , valid precision: 0.789000 , valid loss: 256.828323
epoch: 5 , global_step: 2112 , train loss: 260.118505 , valid precision: 0.803200 , valid loss: 236.345333
epoch: 6 , global_step: 2464 , train loss: 243.392820 , valid precision: 0.816200 , valid loss: 228.309494
epoch: 7 , global_step: 2816 , train loss: 227.717510 , valid precision: 0.826000 , valid loss: 219.518895
epoch: 8 , global_step: 3168 , train loss: 216.411727 , valid precision: 0.840000 , valid loss: 213.196000
epoch: 9 , global_step: 3520 , train loss: 207.480410 , valid precision: 0.844200 , valid loss: 206.555925
epoch: 10 , global_step: 3872 , train loss: 199.971154 , valid precision: 0.845800 , valid loss: 203.910030
epoch: 11 , global_step: 4224 , train loss: 193.991043 , valid precision: 0.853400 , valid loss: 207.069803
epoch: 12 , global_step: 4576 , train loss: 187.521485 , valid precision: 0.858200 , valid loss: 204.683934
epoch: 13 , global_step: 4928 , train loss: 185.200141 , valid precision: 0.845600 , valid loss: 215.120589
epoch: 14 , global_step: 5280 , train loss: 181.545097 , valid precision: 0.863200 , valid loss: 205.252655
epoch: 15 , global_step: 5632 , train loss: 180.413250 , valid precision: 0.864200 , valid loss: 211.941884
epoch: 16 , global_step: 5984 , train loss: 176.240997 , valid precision: 0.861000 , valid loss: 212.918826
epoch: 17 , global_step: 6336 , train loss: 174.910121 , valid precision: 0.871200 , valid loss: 205.237865
epoch: 18 , global_step: 6688 , train loss: 173.381477 , valid precision: 0.871200 , valid loss: 212.132489
epoch: 19 , global_step: 7040 , train loss: 172.325000 , valid precision: 0.862200 , valid loss: 217.282485
epoch: 20 , global_step: 7392 , train loss: 169.617701 , valid precision: 0.872000 , valid loss: 214.292760
epoch: 21 , global_step: 7744 , train loss: 168.266379 , valid precision: 0.877000 , valid loss: 214.606631
epoch: 22 , global_step: 8096 , train loss: 168.084330 , valid precision: 0.878000 , valid loss: 216.094560
epoch: 23 , global_step: 8448 , train loss: 165.961540 , valid precision: 0.880200 , valid loss: 220.895390
epoch: 24 , global_step: 8800 , train loss: 165.612809 , valid precision: 0.877600 , valid loss: 219.785199
epoch: 25 , global_step: 9152 , train loss: 162.385056 , valid precision: 0.885400 , valid loss: 215.318302
epoch: 26 , global_step: 9504 , train loss: 163.204177 , valid precision: 0.884200 , valid loss: 220.777245
epoch: 27 , global_step: 9856 , train loss: 160.596738 , valid precision: 0.887200 , valid loss: 220.681145
epoch: 28 , global_step: 10208 , train loss: 160.442806 , valid precision: 0.885800 , valid loss: 225.210137
epoch: 29 , global_step: 10560 , train loss: 159.137521 , valid precision: 0.885400 , valid loss: 218.838594
epoch: 30 , global_step: 10912 , train loss: 158.872182 , valid precision: 0.887400 , valid loss: 223.702107
epoch: 31 , global_step: 11264 , train loss: 157.733234 , valid precision: 0.882600 , valid loss: 228.412104
epoch: 32 , global_step: 11616 , train loss: 157.449202 , valid precision: 0.885200 , valid loss: 221.543220
epoch: 33 , global_step: 11968 , train loss: 157.435319 , valid precision: 0.888600 , valid loss: 223.934092
epoch: 34 , global_step: 12320 , train loss: 154.027898 , valid precision: 0.891000 , valid loss: 225.135965
epoch: 35 , global_step: 12672 , train loss: 155.405406 , valid precision: 0.887200 , valid loss: 219.601581
epoch: 36 , global_step: 13024 , train loss: 153.039830 , valid precision: 0.885000 , valid loss: 225.806810
epoch: 37 , global_step: 13376 , train loss: 153.899773 , valid precision: 0.885400 , valid loss: 228.504844
epoch: 38 , global_step: 13728 , train loss: 152.995723 , valid precision: 0.887200 , valid loss: 226.533223
epoch: 39 , global_step: 14080 , train loss: 150.668700 , valid precision: 0.887600 , valid loss: 226.059412
epoch: 40 , global_step: 14432 , train loss: 150.780491 , valid precision: 0.887000 , valid loss: 230.339956
epoch: 41 , global_step: 14784 , train loss: 150.764290 , valid precision: 0.885400 , valid loss: 232.365420
