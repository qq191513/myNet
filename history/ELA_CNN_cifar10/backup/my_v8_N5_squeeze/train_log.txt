epoch: 0 , global_step: 352 , train loss: 1359.802347 , valid precision: 0.285800 , valid loss: 1302.297753
epoch: 1 , global_step: 704 , train loss: 1259.198326 , valid precision: 0.358400 , valid loss: 1236.950019
epoch: 2 , global_step: 1056 , train loss: 1213.329479 , valid precision: 0.353200 , valid loss: 1206.605020
epoch: 3 , global_step: 1408 , train loss: 1186.225443 , valid precision: 0.358200 , valid loss: 1205.995204
epoch: 4 , global_step: 1760 , train loss: 1167.466929 , valid precision: 0.399000 , valid loss: 1164.389169
epoch: 5 , global_step: 2112 , train loss: 1150.803573 , valid precision: 0.412600 , valid loss: 1159.294456
epoch: 6 , global_step: 2464 , train loss: 1136.141893 , valid precision: 0.430800 , valid loss: 1131.381165
epoch: 7 , global_step: 2816 , train loss: 1122.819176 , valid precision: 0.458800 , valid loss: 1121.773757
epoch: 8 , global_step: 3168 , train loss: 1108.911656 , valid precision: 0.478400 , valid loss: 1111.660020
epoch: 9 , global_step: 3520 , train loss: 1096.193652 , valid precision: 0.501800 , valid loss: 1098.312231
epoch: 10 , global_step: 3872 , train loss: 1086.253268 , valid precision: 0.532200 , valid loss: 1085.319751
epoch: 11 , global_step: 4224 , train loss: 1076.530305 , valid precision: 0.529200 , valid loss: 1072.282134
epoch: 12 , global_step: 4576 , train loss: 1069.965498 , valid precision: 0.539800 , valid loss: 1064.564352
epoch: 13 , global_step: 4928 , train loss: 1063.323609 , valid precision: 0.534800 , valid loss: 1071.030604
epoch: 14 , global_step: 5280 , train loss: 1058.415013 , valid precision: 0.557000 , valid loss: 1062.043775
epoch: 15 , global_step: 5632 , train loss: 1052.900319 , valid precision: 0.553400 , valid loss: 1058.917579
epoch: 16 , global_step: 5984 , train loss: 1046.986811 , valid precision: 0.563000 , valid loss: 1058.106841
epoch: 17 , global_step: 6336 , train loss: 1045.403738 , valid precision: 0.555800 , valid loss: 1044.752570
epoch: 18 , global_step: 6688 , train loss: 1040.511189 , valid precision: 0.561400 , valid loss: 1050.890970
epoch: 19 , global_step: 7040 , train loss: 1038.681061 , valid precision: 0.567000 , valid loss: 1045.594321
epoch: 20 , global_step: 7392 , train loss: 1035.276976 , valid precision: 0.552000 , valid loss: 1045.804209
epoch: 21 , global_step: 7744 , train loss: 1031.850332 , valid precision: 0.582200 , valid loss: 1036.984332
epoch: 22 , global_step: 8096 , train loss: 1028.723067 , valid precision: 0.565400 , valid loss: 1043.060723
epoch: 23 , global_step: 8448 , train loss: 1025.522200 , valid precision: 0.578800 , valid loss: 1031.460791
epoch: 24 , global_step: 8800 , train loss: 1025.299380 , valid precision: 0.569000 , valid loss: 1040.765871
epoch: 25 , global_step: 9152 , train loss: 1021.701426 , valid precision: 0.570800 , valid loss: 1034.151070
epoch: 26 , global_step: 9504 , train loss: 1018.717386 , valid precision: 0.584400 , valid loss: 1031.818621
epoch: 27 , global_step: 9856 , train loss: 1014.416983 , valid precision: 0.582800 , valid loss: 1033.052093
epoch: 28 , global_step: 10208 , train loss: 1015.014652 , valid precision: 0.573000 , valid loss: 1031.806014
epoch: 29 , global_step: 10560 , train loss: 1012.961812 , valid precision: 0.573200 , valid loss: 1025.707400
epoch: 30 , global_step: 10912 , train loss: 1009.860881 , valid precision: 0.569200 , valid loss: 1033.432056
