epoch: 0 , global_step: 704 , train loss: 371.105960 , valid precision: 0.407400 , valid loss: 290.971204
epoch: 1 , global_step: 1408 , train loss: 266.009590 , valid precision: 0.536800 , valid loss: 226.252126
epoch: 2 , global_step: 2112 , train loss: 221.898389 , valid precision: 0.614600 , valid loss: 191.925587
epoch: 3 , global_step: 2816 , train loss: 197.827247 , valid precision: 0.647200 , valid loss: 174.042537
epoch: 4 , global_step: 3520 , train loss: 181.629454 , valid precision: 0.684800 , valid loss: 161.022387
epoch: 5 , global_step: 4224 , train loss: 171.926998 , valid precision: 0.716600 , valid loss: 151.140073
epoch: 6 , global_step: 4928 , train loss: 162.302539 , valid precision: 0.717400 , valid loss: 148.860561
epoch: 7 , global_step: 5632 , train loss: 158.556358 , valid precision: 0.740600 , valid loss: 143.122291
epoch: 8 , global_step: 6336 , train loss: 152.535588 , valid precision: 0.750000 , valid loss: 142.216273
epoch: 9 , global_step: 7040 , train loss: 148.868019 , valid precision: 0.753600 , valid loss: 141.448760
epoch: 10 , global_step: 7744 , train loss: 146.113768 , valid precision: 0.762000 , valid loss: 138.414380
epoch: 11 , global_step: 8448 , train loss: 143.427146 , valid precision: 0.762800 , valid loss: 138.874572
epoch: 12 , global_step: 9152 , train loss: 139.837099 , valid precision: 0.777200 , valid loss: 134.260481
epoch: 13 , global_step: 9856 , train loss: 136.928859 , valid precision: 0.772000 , valid loss: 132.125789
epoch: 14 , global_step: 10560 , train loss: 134.362727 , valid precision: 0.781400 , valid loss: 133.190149
epoch: 15 , global_step: 11264 , train loss: 133.164304 , valid precision: 0.778800 , valid loss: 133.158920
epoch: 16 , global_step: 11968 , train loss: 131.464032 , valid precision: 0.784400 , valid loss: 130.640422
epoch: 17 , global_step: 12672 , train loss: 129.056158 , valid precision: 0.791600 , valid loss: 129.898054
epoch: 18 , global_step: 13376 , train loss: 127.627800 , valid precision: 0.790800 , valid loss: 131.129036
epoch: 19 , global_step: 14080 , train loss: 125.897943 , valid precision: 0.794200 , valid loss: 127.459848
epoch: 20 , global_step: 14784 , train loss: 124.959358 , valid precision: 0.798400 , valid loss: 127.870049
epoch: 21 , global_step: 15488 , train loss: 123.501275 , valid precision: 0.805200 , valid loss: 128.018443
epoch: 22 , global_step: 16192 , train loss: 121.995774 , valid precision: 0.803600 , valid loss: 125.925837
epoch: 23 , global_step: 16896 , train loss: 121.556069 , valid precision: 0.808600 , valid loss: 125.342126
epoch: 24 , global_step: 17600 , train loss: 121.163835 , valid precision: 0.809000 , valid loss: 125.945136
epoch: 25 , global_step: 18304 , train loss: 119.205008 , valid precision: 0.808600 , valid loss: 124.375864
epoch: 26 , global_step: 19008 , train loss: 118.288218 , valid precision: 0.804800 , valid loss: 124.291579
epoch: 27 , global_step: 19712 , train loss: 117.239697 , valid precision: 0.801600 , valid loss: 125.818300
epoch: 28 , global_step: 20416 , train loss: 116.971676 , valid precision: 0.821800 , valid loss: 122.578619
epoch: 29 , global_step: 21120 , train loss: 116.100432 , valid precision: 0.820200 , valid loss: 122.932095
epoch: 30 , global_step: 21824 , train loss: 114.945070 , valid precision: 0.819600 , valid loss: 121.306599
