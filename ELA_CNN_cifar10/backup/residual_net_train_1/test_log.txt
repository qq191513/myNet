epoch: 0 , global_step: 352 , train loss: 243.161566 , valid precision: 0.503400 , valid loss: 181.269600
epoch: 1 , global_step: 704 , train loss: 166.504721 , valid precision: 0.635800 , valid loss: 136.207235
epoch: 2 , global_step: 1056 , train loss: 136.713497 , valid precision: 0.694800 , valid loss: 116.027881
epoch: 3 , global_step: 1408 , train loss: 116.636110 , valid precision: 0.741400 , valid loss: 97.815889
epoch: 4 , global_step: 1760 , train loss: 100.980083 , valid precision: 0.771000 , valid loss: 88.589360
epoch: 5 , global_step: 2112 , train loss: 89.323940 , valid precision: 0.790600 , valid loss: 81.687966
epoch: 6 , global_step: 2464 , train loss: 82.378313 , valid precision: 0.813600 , valid loss: 75.075734
epoch: 7 , global_step: 2816 , train loss: 77.129925 , valid precision: 0.813800 , valid loss: 74.844068
epoch: 8 , global_step: 3168 , train loss: 71.423407 , valid precision: 0.836400 , valid loss: 69.582562
epoch: 9 , global_step: 3520 , train loss: 68.236547 , valid precision: 0.841400 , valid loss: 71.641066
epoch: 10 , global_step: 3872 , train loss: 66.419417 , valid precision: 0.840600 , valid loss: 71.222252
epoch: 11 , global_step: 4224 , train loss: 64.298059 , valid precision: 0.853800 , valid loss: 67.690292
epoch: 12 , global_step: 4576 , train loss: 62.955171 , valid precision: 0.857600 , valid loss: 67.919446
epoch: 13 , global_step: 4928 , train loss: 61.766473 , valid precision: 0.866000 , valid loss: 66.001013
epoch: 14 , global_step: 5280 , train loss: 60.942653 , valid precision: 0.868600 , valid loss: 66.761192
epoch: 15 , global_step: 5632 , train loss: 59.534173 , valid precision: 0.865000 , valid loss: 68.608532
epoch: 16 , global_step: 5984 , train loss: 58.735901 , valid precision: 0.867400 , valid loss: 69.849264
epoch: 17 , global_step: 6336 , train loss: 58.293437 , valid precision: 0.874600 , valid loss: 66.788067
epoch: 18 , global_step: 6688 , train loss: 57.353353 , valid precision: 0.875200 , valid loss: 68.843658
epoch: 19 , global_step: 7040 , train loss: 57.500830 , valid precision: 0.877400 , valid loss: 68.017784
epoch: 20 , global_step: 7392 , train loss: 56.623533 , valid precision: 0.875800 , valid loss: 71.005765
epoch: 21 , global_step: 7744 , train loss: 56.438944 , valid precision: 0.874800 , valid loss: 71.960430
epoch: 22 , global_step: 8096 , train loss: 55.951891 , valid precision: 0.879600 , valid loss: 71.654186
epoch: 23 , global_step: 8448 , train loss: 55.781022 , valid precision: 0.878800 , valid loss: 71.739166
epoch: 24 , global_step: 8800 , train loss: 55.977613 , valid precision: 0.886200 , valid loss: 71.089605
epoch: 25 , global_step: 9152 , train loss: 54.853540 , valid precision: 0.878400 , valid loss: 75.027569
epoch: 26 , global_step: 9504 , train loss: 54.798146 , valid precision: 0.880800 , valid loss: 75.734224
epoch: 27 , global_step: 9856 , train loss: 54.934901 , valid precision: 0.878600 , valid loss: 75.182568
epoch: 28 , global_step: 10208 , train loss: 54.291466 , valid precision: 0.887400 , valid loss: 72.919915
epoch: 29 , global_step: 10560 , train loss: 54.452908 , valid precision: 0.888200 , valid loss: 72.508589
epoch: 30 , global_step: 10912 , train loss: 53.537161 , valid precision: 0.882000 , valid loss: 77.544421
epoch: 31 , global_step: 11264 , train loss: 53.063568 , valid precision: 0.886000 , valid loss: 77.136024
epoch: 32 , global_step: 11616 , train loss: 53.071586 , valid precision: 0.889600 , valid loss: 74.543984
epoch: 33 , global_step: 11968 , train loss: 52.250735 , valid precision: 0.888400 , valid loss: 74.801080
epoch: 34 , global_step: 12320 , train loss: 53.110352 , valid precision: 0.881800 , valid loss: 79.031222
epoch: 35 , global_step: 12672 , train loss: 52.597268 , valid precision: 0.877600 , valid loss: 78.706725
epoch: 36 , global_step: 13024 , train loss: 52.309784 , valid precision: 0.884000 , valid loss: 76.935548
epoch: 37 , global_step: 13376 , train loss: 52.242607 , valid precision: 0.888800 , valid loss: 76.020486
epoch: 38 , global_step: 13728 , train loss: 52.568474 , valid precision: 0.888400 , valid loss: 76.266341
epoch: 39 , global_step: 14080 , train loss: 51.847761 , valid precision: 0.882200 , valid loss: 79.978352
epoch: 40 , global_step: 14432 , train loss: 51.347265 , valid precision: 0.889800 , valid loss: 76.374855
