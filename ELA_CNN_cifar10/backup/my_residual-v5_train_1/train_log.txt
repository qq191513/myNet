epoch: 0 , global_step: 704 , train loss: 402.188465 , valid precision: 0.445000 , valid loss: 293.290892
epoch: 1 , global_step: 1408 , train loss: 265.819919 , valid precision: 0.610600 , valid loss: 224.296934
epoch: 2 , global_step: 2112 , train loss: 213.080015 , valid precision: 0.674200 , valid loss: 187.000776
epoch: 3 , global_step: 2816 , train loss: 184.230939 , valid precision: 0.752600 , valid loss: 156.422563
epoch: 4 , global_step: 3520 , train loss: 164.561168 , valid precision: 0.769000 , valid loss: 148.640272
epoch: 5 , global_step: 4224 , train loss: 154.314189 , valid precision: 0.791200 , valid loss: 141.900492
epoch: 6 , global_step: 4928 , train loss: 147.300710 , valid precision: 0.804800 , valid loss: 139.802993
epoch: 7 , global_step: 5632 , train loss: 142.466897 , valid precision: 0.811600 , valid loss: 136.950707
epoch: 8 , global_step: 6336 , train loss: 139.527201 , valid precision: 0.816600 , valid loss: 140.698383
epoch: 9 , global_step: 7040 , train loss: 136.112022 , valid precision: 0.821400 , valid loss: 137.991936
epoch: 10 , global_step: 7744 , train loss: 133.039660 , valid precision: 0.825000 , valid loss: 136.131136
epoch: 11 , global_step: 8448 , train loss: 130.127487 , valid precision: 0.830600 , valid loss: 136.611673
epoch: 12 , global_step: 9152 , train loss: 127.894818 , valid precision: 0.839200 , valid loss: 132.214752
epoch: 13 , global_step: 9856 , train loss: 125.600261 , valid precision: 0.839000 , valid loss: 131.354540
epoch: 14 , global_step: 10560 , train loss: 124.439677 , valid precision: 0.847400 , valid loss: 132.413661
epoch: 15 , global_step: 11264 , train loss: 121.799734 , valid precision: 0.857400 , valid loss: 129.912526
epoch: 16 , global_step: 11968 , train loss: 119.729633 , valid precision: 0.855600 , valid loss: 129.855530
epoch: 17 , global_step: 12672 , train loss: 119.423191 , valid precision: 0.858400 , valid loss: 127.093364
epoch: 18 , global_step: 13376 , train loss: 115.985264 , valid precision: 0.859000 , valid loss: 129.462138
epoch: 19 , global_step: 14080 , train loss: 115.118278 , valid precision: 0.858800 , valid loss: 126.712520
epoch: 20 , global_step: 14784 , train loss: 113.427798 , valid precision: 0.850400 , valid loss: 130.647495
epoch: 21 , global_step: 15488 , train loss: 112.791051 , valid precision: 0.860800 , valid loss: 128.063470
epoch: 22 , global_step: 16192 , train loss: 111.372395 , valid precision: 0.863000 , valid loss: 127.206399
epoch: 23 , global_step: 16896 , train loss: 111.779761 , valid precision: 0.858400 , valid loss: 127.277484
epoch: 24 , global_step: 17600 , train loss: 110.396965 , valid precision: 0.862400 , valid loss: 124.066000
epoch: 25 , global_step: 18304 , train loss: 109.092211 , valid precision: 0.865600 , valid loss: 123.374282
epoch: 26 , global_step: 19008 , train loss: 108.262314 , valid precision: 0.869800 , valid loss: 124.052291
epoch: 27 , global_step: 19712 , train loss: 107.402667 , valid precision: 0.870800 , valid loss: 124.269250
epoch: 28 , global_step: 20416 , train loss: 107.432934 , valid precision: 0.862200 , valid loss: 126.083352
epoch: 29 , global_step: 21120 , train loss: 105.520183 , valid precision: 0.867600 , valid loss: 127.102483
epoch: 30 , global_step: 21824 , train loss: 105.455730 , valid precision: 0.866600 , valid loss: 126.918042
epoch: 31 , global_step: 22528 , train loss: 105.356174 , valid precision: 0.872000 , valid loss: 127.819765
epoch: 32 , global_step: 23232 , train loss: 104.801698 , valid precision: 0.866200 , valid loss: 123.845704
